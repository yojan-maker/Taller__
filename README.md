# ğŸ“ README â€” Punto: SimulaciÃ³n de robots SoftBank con `humanoid-gym` + Docker

## ğŸ“Œ IntroducciÃ³n

En este punto del laboratorio se solicitÃ³:

> **â€œDesarrollar la simulaciÃ³n de los robots de SoftBank Robotics del repositorio denominado `humanoid-gym` y desplegarlos en Docker.â€**

Los robots involucrados en el proyecto de simulaciÃ³n son:

* **Pepper**
* **Nao**
* **Romeo**
* **Dancer**

Todos ellos supuestamente simulables mediante el proyecto de GitHub:

ğŸ”— [https://github.com/0aqz0/humanoid-gym](https://github.com/0aqz0/humanoid-gym)

Sin embargo, al intentar utilizar y dockerizar este repositorio, fue necesario realizar una **revisiÃ³n tÃ©cnica** debido a mÃºltiples errores


Se detallara:

* **âœ” QuÃ© se intentÃ³**
* **âœ” QuÃ© errores aparecieron**
* **âœ” Por quÃ© no funciona**
* **âœ” QuÃ© limitaciones tÃ©cnicas existen**

---

## ğŸ§© 1. Â¿QuÃ© es `humanoid-gym`?

`humanoid-gym` es un repositorio creado hace varios aÃ±os (**Ãºltimo *commit* hace 4 aÃ±os**) que promete ofrecer **entornos Gym** basados en **PyBullet** para robots humanoides de SoftBank.

Incluye:
* Archivos **URDFs** de Pepper, Nao, Romeo y Dancer.
* *Scripts* para crear entornos Gym con acciones y observaciones.
* Ejemplos de uso con PyBullet.

Sin embargo, el repositorio **NO se ha actualizado** desde:
* Python **3.6 / 3.7**
* Gym **0.15**
* PyBullet de **2019**
* Versiones antiguas de GLFW, mesa, etc.

---

## â— 2. Por quÃ© no funciona hoy en 2025

Durante el taller se intentÃ³ ejecutar y dockerizar el proyecto usando:

* Ubuntu **22.04 / 24.04** base
* Python **3.11**
* PyBullet **reciente**
* Gym **actual**
* Docker moderno

Y los errores se repitieron cada vez, incluso con distintas variantes del `Dockerfile`.

Los problemas principales fueron:

### ğŸš« Problema 1 â€” Dependencias del sistema obsoletas

El repositorio requiere librerÃ­as del sistema que ya **NO existen** en las versiones modernas de Ubuntu:

**Ejemplos:**
* `libgl1-mesa-glx`
* `libosmesa6`
* `libglfw3`
* *Drivers* *dummy* para OpenGL
* Viejas versiones de `mesa-utils`

Muchos paquetes fueron **eliminados o renombrados** â†’ el *build* falla en la etapa de instalaciÃ³n de librerÃ­as del sistema.

### ğŸš« Problema 2 â€” PyBullet cambiÃ³ completamente

Las versiones nuevas de PyBullet introducen cambios drÃ¡sticos que rompen la compatibilidad con el cÃ³digo antiguo:

* Cambiaron funciones de inicializaciÃ³n.
* Requieren **EGL / OSMesa modernos** para la renderizaciÃ³n sin cabecera (headless).
* Cambiaron la forma en que Gym registra entornos.
* Eliminan soporte para versiones antiguas de OpenGL *dummy*.

### ğŸš« Problema 3 â€” Gym dejÃ³ de soportar ese API

El repositorio usa la forma antigua de registrar y usar entornos: `gym.make('pepper-v0')`.

Pero Gym (versiones superiores a 0.26) requiere:
* Registro explÃ­cito.
* Uso de *spaces* nuevos.
* API `step()` diferente (ahora retorna **5 valores**).

> Esto causa errores de tipo: `TypeError: step() takes 4 positional arguments but 5 were given`

### ğŸš« Problema 4 â€” Dependencias Python incompatibles

El comando `pip install -e .` intenta instalar dependencias que ya no existen o son incompatibles con Python moderno:

* `gym==0.15`
* `pybullet==2.5.5`
* `numpy<1.16`
* `setuptools` antiguo

Esto produce una **cascada de fallos en pip** y en el entorno de Python.

### ğŸš« Problema 5 â€” El repositorio NO incluye el cÃ³digo completo

La estructura interna del repositorio estÃ¡ incompleta o mal referenciada:

* No trae los **URDF originales de SoftBank**.
* Las carpetas `pepper` / `nao` estÃ¡n solo **parcialmente definidas**.
* Las imÃ¡genes de previsualizaciÃ³n existen, pero los modelos (archivos URDF/SDF completos) no.
* Falta la carpeta de *assets* interna de `qibullet` (la librerÃ­a de simulaciÃ³n real).

## âœ” QuÃ© se intentÃ³

Durante el taller se intentaron varias estrategias para mitigar los problemas del repositorio obsoleto:

### 1. ClonaciÃ³n y ReorganizaciÃ³n del Proyecto
* **âœ” ClonaciÃ³n del repo:** `git clone https://github.com/0aqz0/humanoid-gym`
* **âœ” ReorganizaciÃ³n del proyecto:**
    * Se crearon estructuras limpias para el proyecto con el fin de aislar la simulaciÃ³n:
        * `app/`
        * `robots/`
        * `docker/`
        * `assets/`

### 2. PersonalizaciÃ³n de Dependencias
* **âœ” `Requirements` personalizados:**
    * Se intentÃ³ forzar el uso de versiones de librerÃ­as que podrÃ­an ser compatibles con Python moderno, incluyendo:
        * **PyBullet** (varias versiones)
        * **Gym retro**
        * **`glfw`**
        * **`numpy`** (versiones antiguas especÃ­ficas)

### 3. Pruebas de Despliegue en Docker
* **âœ” Varios `Dockerfiles` probados:**
    * Se utilizaron distintas imÃ¡genes base de Docker para el *build*:
        * `python:3.11-slim`
        * `python:3.10`
        * `ubuntu:22.04` + instalaciÃ³n manual de Python

> **Resultado:** Todas las variantes de Dockerfiles reproducÃ­an los errores de dependencias mencionados previamente.

### 4. Entorno local
* **âœ” Se intentÃ³ recrear el entorno sin Docker:**
    * Incluso en un entorno local (fuera de Docker), configurando manualmente las versiones de librerÃ­as, el proyecto **tampoco funcionÃ³**, confirmando que la incompatibilidad es inherente al cÃ³digo obsoleto.

---

## ğŸ§¨ 4. ConclusiÃ³n TÃ©cnica

Tras mÃºltiples pruebas de ejecuciÃ³n y dockerizaciÃ³n en entornos modernos:

> **Este repositorio estÃ¡ obsoleto y no puede ser ejecutado en sistemas modernos.** Tampoco puede ser dockerizado de forma efectiva porque sus dependencias estÃ¡n rotas, eliminadas o son incompatibles con las versiones actuales de PyBullet y Gym.


# ğŸ“Œ PUNTO 2 â€” Desarrollo de un Algoritmo de SegmentaciÃ³n
---

Este punto del taller consistiÃ³ en desarrollar un sistema completo capaz de:

* **Detectar** multÃ­metros, osciloscopios y **Raspberry Pi** usando un modelo entrenado con **YOLO**.
* Generar una **segmentaciÃ³n aproximada** a partir de la detecciÃ³n YOLO.
* Usar **hilos** (`threads`) para procesar la cÃ¡mara en paralelo.
* Evitar **condiciones de carrera** mediante `locks`.
* Visualizar todo en **tiempo real** mediante **Streamlit**.
* Preparar el sistema para ser **desplegado dentro de Docker**.

El sistema final cumple con todos los requerimientos y funciona en **tiempo real**.

## ğŸ¯ Objetivo General

Implementar un algoritmo de segmentaciÃ³n aplicando:

* **Ubuntu Linux**
* **Hilos y concurrencia**
* **SemaforizaciÃ³n / mutex**
* **VisiÃ³n por computadora**
* **YOLO** (modelo entrenado en Roboflow + Google Colab)
* **Streamlit** para la interfaz
* **Docker** para despliegue del sistema

---

## ğŸ§© DescripciÃ³n del Dashboard

El dashboard desarrollado en Streamlit permite:

### âœ” Visualizar detecciÃ³n en tiempo real
* Se muestran las **cajas** (`bounding boxes`) generadas por YOLO.
* Se identifica el tipo de dispositivo (**multÃ­metro**, **osciloscopio**, **Raspberry Pi**).

### âœ” Obtener segmentaciÃ³n aproximada
* Se genera una **mÃ¡scara (segmentaciÃ³n)** usando el Ã¡rea del `bounding box`.
* La segmentaciÃ³n **resalta Ãºnicamente el objeto detectado**. 

### âœ” EjecuciÃ³n multihilo
* La cÃ¡mara se procesa en un **hilo dedicado**.
* La interfaz **Streamlit nunca se bloquea**.

### âœ” Sistema listo para Docker
* El proyecto incluye un **Dockerfile** y `requirements.txt` listos para despliegue.

## ğŸ“‚ Estructura del Proyecto: SegmentaciÃ³n

```bash
segmentacion/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ dashboard.py              # Interfaz de usuario **Streamlit**
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile                # Archivo para la **DockerizaciÃ³n**
â”‚   â””â”€â”€ requirements.txt          # Dependencias del proyecto
â”œâ”€â”€ model/
â”‚   â””â”€â”€ best.pt                   # Modelo **YOLO** entrenado
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ camera_thread.py          # **Hilo dedicado** de captura de cÃ¡mara
â”‚   â”œâ”€â”€ detector_yolo.py          # Detector YOLO
â”‚   â”œâ”€â”€ pipeline.py               # **Pipeline** de procesamiento (hilos + detecciÃ³n + segmentaciÃ³n)
â”‚   â””â”€â”€ segmentador_simple.py     # LÃ³gica de **SegmentaciÃ³n** basada en YOLO
â”œâ”€â”€ main.py                       # Punto de entrada principal
â””â”€â”€ utils.py                      # Funciones de utilidad
```

# ğŸš€ Proceso Completo Realizado
  
## 1ï¸âƒ£ Entrenamiento del modelo YOLO

### ğŸ“¸ Captura y AnotaciÃ³n de Datos
* Se capturaron **imÃ¡genes** de multÃ­metros, osciloscopios y Raspberry Pi.
* Se subieron a **Roboflow**, donde fueron **anotadas manualmente**.
* Se generaron **tres versiones** del *dataset* con diferentes tamaÃ±os.

### âŒ Dificultad con la ExportaciÃ³n
Se intentÃ³ descargar los pesos desde Roboflow, pero:
> âŒ **Roboflow** pedÃ­a plan de pago para exportar el archivo de pesos (`.pt`).

### âœ” SoluciÃ³n: Entrenamiento en Google Colab
* **SoluciÃ³n:** Entrenar el modelo de forma **gratuita** en **Google Colab** usando la librerÃ­a **ultralytics**.

### ğŸ’» Pasos del Entrenamiento
* Se utilizÃ³ **Google Colab GPU**.
* Se cargÃ³ el *dataset* desde Roboflow (en formato **YOLOv8**).
* Se obtuvo el modelo final, guardado como:
  > `best.pt`

## 2ï¸âƒ£ Intento fallido con MediaPipe

Se probÃ³ integrar **MediaPipe Image Segmenter**.

### âŒ Problemas encontrados:
* MediaPipe solo segmenta **personas**, cabello, rostro, piel o ropa.
* Los modelos **NO segmentan objetos** como multÃ­metros u osciloscopios.
* Intentar usar un modelo propio requiere un archivo `.tflite` entrenado, el cual no estaba disponible.
* Los modelos preentrenados de MediaPipe generaban mÃ¡scaras completamente blancas.

### âœ” SoluciÃ³n
Se decidiÃ³ **no usar MediaPipe**, por no ser adecuado para la segmentaciÃ³n de objetos electrÃ³nicos especÃ­ficos.

---

## 3ï¸âƒ£ SegmentaciÃ³n simplificada basada en YOLO

Para cumplir con el objetivo del taller sin un modelo de segmentaciÃ³n *instance* dedicado:

### âœ” Enfoque adoptado:
* Se usa **YOLO** para la **detecciÃ³n** (generar el *bounding box*).
* Se crea una **"segmentaciÃ³n falsa"** o simplificada **resaltando Ãºnicamente el Ã¡rea de la caja detectada**.
* Esto genera una mÃ¡scara totalmente vÃ¡lida para fines acadÃ©micos. 

### ğŸ¨ Ejemplo de MÃ¡scara Generada:
* Todo fuera de la caja â†’ **Negro**
* Todo dentro de la caja â†’ **Blanco**

---

## 4ï¸âƒ£ ImplementaciÃ³n con hilos y concurrencia

Para lograr el procesamiento en tiempo real sin bloquear la interfaz:

### ğŸ”¸ `CameraThread`
* Captura imÃ¡genes sin bloquear la interfaz.
* Corre en un **hilo independiente**.

### ğŸ”¸ `Pipeline`
* Protege las variables compartidas con `threading.Lock()` (SemÃ¡foro).
* **Evita condiciones de carrera** al acceder al *frame* de la cÃ¡mara.
* Contiene la lÃ³gica de **YOLO + SegmentaciÃ³n**.

---

## 5ï¸âƒ£ Dashboard en Streamlit

La interfaz de usuario implementada:
* Muestra las **detecciones en tiempo real**.
* Muestra la **mÃ¡scara de segmentaciÃ³n**.
* Muestra el **FPS** (Frames por Segundo) aproximado.
* **No se bloquea** gracias al pipeline multihilo.

---

## 6ï¸âƒ£ DockerizaciÃ³n

Se preparÃ³ la aplicaciÃ³n para un despliegue portable:

### ğŸ›  ConfiguraciÃ³n de Docker
* `Dockerfile` con imagen base **Python 3.11** (o la versiÃ³n que hayas usado).
* InstalaciÃ³n de **OpenCV**, **ultralytics**, y demÃ¡s librerÃ­as en un entorno aislado.
* **ExposiciÃ³n** del dashboard en el puerto **8501**.

### âš™ Comandos de Docker (Pendientes de aÃ±adir)

```bash
docker build -t segmentacion 
docker run -p 8501:8501 segmentacion
```

| Problema | Causa | SoluciÃ³n |
| :--- | :--- | :--- |
| **Roboflow no descarga .pt** | Requiere plan pago | **Entrenar gratis en Google Colab** |
| **MediaPipe daba mÃ¡scaras blancas** | No segmenta objetos electrÃ³nicos | **Reemplazar por segmentaciÃ³n basada en YOLO** |
| **`ModuleNotFoundError: src`** | Dashboard se ejecutaba desde carpeta incorrecta | **Agregar `sys.path.append(BASE_DIR)`** |
| **No encontraba modelo YOLO** | Carpeta equivocada (`models` vs `model`) | **Establecer estructura fija y corregir rutas** |
| **Streamlit no mostraba nada** | Bloqueo por captura de cÃ¡mara | **`Thread` dedicado para cÃ¡mara** |
| **SegmentaciÃ³n invisible** | MediaPipe devolvÃ­a fondo plano | **Cambiar a segmentador simple** |

# ğŸ§  ConclusiÃ³n del Punto 2

Este punto del taller permitiÃ³ construir un **sistema completo de detecciÃ³n y segmentaciÃ³n** aplicando los siguientes pilares tecnolÃ³gicos:

* **VisiÃ³n por computadora**
* Entrenamiento de **modelos YOLO**
* **Concurrencia** mediante **hilos**
* **SincronizaciÃ³n** con `locks` (SemÃ¡foros)
* Despliegue profesional en **Docker**
* Interfaz interactiva en **Streamlit**

---

A pesar de las **dificultades tÃ©cnicas** â€”como incompatibilidades con MediaPipe, problemas con rutas, modelos no compatibles y restricciones de Roboflowâ€” se logrÃ³ un sistema bastante **funcional**, y capaz de ejecutarse en **tiempo real**.

---

![Image](https://github.com/user-attachments/assets/0f23104d-93a5-4a97-887c-118ec77487c5)
 > `Entrenamiento YOLO`

![Image](https://github.com/user-attachments/assets/f83b8738-08da-47d6-b4db-55774eac1ff9)
 > `Prueba de segmentacion con mediapipe (multimetro)`

![Image](https://github.com/user-attachments/assets/4851f70f-0183-4fd9-a7d3-3c4030ef6c43)
 > `Prueba de segmentacion con mediapipe (osciloscopio)`

![Image](https://github.com/user-attachments/assets/5de7dfc2-6a6e-4e39-9058-f1e921c33c84)
 > `Prueba de segmentacion con mediapipe (raspberri)`

![Image](https://github.com/user-attachments/assets/371ebc86-4898-4bbc-a61f-40b61f6e3428)
 > `Prueba de segmentacion sin mediapipe (osciloscopio)`

![Image](https://github.com/user-attachments/assets/b9b75cfe-5277-48ed-a7d7-1244d02e813f)
 > `Prueba de segmentacion sin mediapipe (multimetro)`

![Image](https://github.com/user-attachments/assets/29de0ada-e716-4540-8783-6775fe7bcdd7)
 > `Prueba de segmentacion sin mediapipe (raspberri)`

------------

## 3. Kubernetes y Desá¹•liegues de juego multijugador

## ğŸŒ Â¿QuÃ© es Kubernetes?

Kubernetes (tambiÃ©n conocido como K8s) es una plataforma open-source diseÃ±ada para automatizar el despliegue, escalado, y administraciÃ³n de aplicaciones en contenedores.
Fue desarrollada originalmente por Google y ahora es mantenida por la Cloud Native Computing Foundation (CNCF).
Su objetivo principal es facilitar la gestiÃ³n de contenedores en entornos de producciÃ³n, especialmente cuando son muchos.

------------

### ğŸ§© DefiniciÃ³n

Kubernetes es un orquestador de contenedores que se encarga de distribuir, ejecutar, monitorear y escalar aplicaciones que estÃ¡n empaquetadas en contenedores (como Docker).
Permite administrar mÃºltiples contenedores de forma coordinada, confiable y automatizada.

------------

## ğŸš€ CaracterÃ­sticas principales de Kubernetes

| ğŸŒŸ CaracterÃ­stica                           | ğŸ“˜ DescripciÃ³n                                                                                       |
| ------------------------------------------- | ---------------------------------------------------------------------------------------------------- |
| **Escalabilidad automÃ¡tica (Auto-Scaling)** | Kubernetes es capaz de aumentar o disminuir el nÃºmero de contenedores segÃºn la carga de trabajo.     |
| **AutorreparaciÃ³n (Self-Healing)**          | Reinicia contenedores fallidos, reemplaza los daÃ±ados y evita mandar trÃ¡fico a los que no funcionan. |
| **Balanceo de carga**                       | Distribuye trÃ¡fico entre contenedores de forma eficiente para evitar sobrecargas.                    |
| **Despliegues continuos (Rolling Updates)** | Permite actualizar aplicaciones sin detener el servicio.                                             |
| **GestiÃ³n declarativa**                     | Todo se maneja con archivos YAML donde defines *quÃ© quieres* que pase, y Kubernetes se encarga.      |
| **Portabilidad**                            | Funciona en la nube, servidores locales o entornos hÃ­bridos.                                         |
| **Escalado horizontal**                     | FÃ¡cilmente puedes tener mÃ¡s instancias de tus aplicaciones segÃºn lo necesites.                       |

------------

## ğŸ› ï¸ Aplicaciones de Kubernetes

Kubernetes se usa ampliamente en entornos modernos de desarrollo y producciÃ³n:

- ğŸ§ª Microservicios
- ğŸ“¦ Aplicaciones basadas en contenedores (Docker)
- â˜ï¸ Despliegues en la nube (AWS, GCP, Azure)
- ğŸ”„ IntegraciÃ³n continua (CI/CD)
- ğŸ­ AutomatizaciÃ³n de despliegue en entornos empresariales
- ğŸ“¡ Aplicaciones distribuidas a gran escala
- ğŸ§  Sistemas de inteligencia artificial y anÃ¡lisis de datos

------------

## ğŸ“¦ RelaciÃ³n entre Kubernetes y los Contenedores

Kubernetes no crea contenedores, sino que los orquesta.

| Contenedores ğŸ³                                           | Kubernetes âš™ï¸                                               |
| --------------------------------------------------------- | ----------------------------------------------------------- |
| AÃ­slan aplicaciones empacadas con todas sus dependencias. | Administra, distribuye y escala esos contenedores.          |
| Ejemplo: Docker                                           | Funciona sobre Docker u otros runtimes (containerd, CRI-O). |
| Solo ejecutan la app.                                     | Se encargan del *cÃ³mo*, *cuÃ¡ndo* y *dÃ³nde* ejecutarlas.     |

En pocas palabras:

Docker crea los contenedores; Kubernetes los organiza, automatiza y escala.

------------


## ğŸ³ CÃ³mo crear contenedores con Docker â€” Paso a paso y conceptos clave

En esta secciÃ³n encontrarÃ¡s una guÃ­a clara y prÃ¡ctica para crear contenedores usando Docker, con un ejemplo sencillo, comandos Ãºtiles y la explicaciÃ³n de los conceptos mÃ¡s importantes.

------------


### ğŸ”§ Resumen rÃ¡pido

1. Crear una pequeÃ±a aplicaciÃ³n (ejemplo: Python/Flask).
2. Escribir un Dockerfile que describa cÃ³mo construir la imagen.
3. Construir la imagen con docker build.
4. Ejecutar un contenedor con docker run.

------------


### ğŸ§© Ejemplo prÃ¡ctico â€” AplicaciÃ³n simple en Python (Flask)

1) Estructura del proyecto

mi-app/ â”œâ”€â”€ app.py â”œâ”€â”€ requirements.txt â””â”€â”€ Dockerfile

app.py

    from flask import Flask app = Flask(__name__) @app.route("/") def hello(): return "Â¡Hola desde Docker! ğŸš€" if __name__ == "__main__": app.run(host="0.0.0.0", port=5000)

requirements.txt

    Flask==2.2.5

Dockerfile

    # Imagen base
    FROM python:3.11-slim
    
    # Directorio de trabajo
    WORKDIR /app
    
    # Copiar dependencias y aplicacion
    COPY requirements.txt .
    RUN pip install --no-cache-dir -r requirements.txt
    
    COPY app.py .
    
    # Exponer puerto y comando por defecto
    
    EXPOSE 5000
    CMD ["python", "app.py"]

2) Construir la imagen

Desde la carpeta mi-app/:

    docker build -t miusuario/mi-app:1.0 .


- -t miusuario/mi-app:1.0 etiqueta la imagen (user/repo).
- El . indica el contexto (carpeta actual).

3) Ejecutar el contenedor

    docker run --rm -p 5000:5000 miusuario/mi-app:1.0

- -p 5000:5000 mapea el puerto del contenedor al host.
- --rm elimina el contenedor al detenerlo.
- Accede en tu navegador: http://localhost:5000

------------

### ğŸ“š Conceptos clave de Docker

|                Concepto | QuÃ© es / Por quÃ© importa                                                                                       |
| ----------------------: | -------------------------------------------------------------------------------------------------------------- |
|              **Imagen** | Plantilla inmutable que contiene la app + dependencias (como un snapshot). Se construye desde un `Dockerfile`. |
|          **Contenedor** | Instancia ejecutable de una imagen. Es efÃ­mero: puedes crear, ejecutar y destruir contenedores.                |
|          **Dockerfile** | Archivo con instrucciones que Docker usa para construir una imagen (COPY, RUN, CMD, EXPOSE, etc.).             |
| **Registro (Registry)** | Servicio donde se almacenan imÃ¡genes (Docker Hub, GitHub Container Registry, registro privado).                |
|                 **Tag** | VersiÃ³n o etiqueta de una imagen (`:1.0`, `:latest`). Facilita versionado y despliegue.                        |
|             **Volumen** | Mecanismo para persistir datos fuera del contenedor (para bases de datos, logs, etc.).                         |
|               **Redes** | Permiten comunicar contenedores entre sÃ­ o con el host.                                                        |
|        **Capa (layer)** | Cada instrucciÃ³n del Dockerfile crea una capa; Docker las cachea para acelerar builds.                         |
|   **Contexto de build** | Archivos que Docker puede acceder durante `docker build` (normalmente la carpeta donde ejecutas el comando).   |
|       **.dockerignore** | Archivo que evita que archivos innecesarios entren al contexto de build (similar a `.gitignore`).              |

------------


### ğŸ® ImplementaciÃ³n del Servidor Multijugador con Kubernetes

En esta parte del proyecto se desarrollÃ³ y desplegÃ³ un servidor de juego multijugador en tiempo real utilizando Node.js, Socket.IO, Docker y Kubernetes (Minikube). El objetivo fue demostrar cÃ³mo un servicio interactivo puede escalar en mÃºltiples rÃ©plicas dentro de un clÃºster.

------------

### ğŸ§© Â¿CÃ³mo funciona el juego?

El servidor implementa un juego extremadamente simple donde cada cliente representa un jugador que posee una posiciÃ³n (x, y) dentro de un plano bÃ¡sico.
Cuando un usuario se conecta:

- Se le asigna un ID Ãºnico generado por Socket.IO.
- Se registra su posiciÃ³n inicial.
- El servidor escucha los movimientos enviados por el cliente (move).
- Actualiza la informaciÃ³n global de todos los jugadores.
- EnvÃ­a el nuevo estado a todos los clientes conectados.

------------

### ğŸ› ï¸ TecnologÃ­as usadas

| TecnologÃ­a                | Uso en el proyecto                                    |
| ------------------------- | ----------------------------------------------------- |
| **Node.js**               | ConstrucciÃ³n del servidor del juego                   |
| **Express**               | Manejo de rutas HTTP bÃ¡sicas                          |
| **Socket.IO**             | ComunicaciÃ³n en tiempo real entre jugadores           |
| **Docker**                | Empaquetamiento del servidor en una imagen ejecutable |
| **Kubernetes (Minikube)** | OrquestaciÃ³n y despliegue escalable con rÃ©plicas      |
| **NodePort Service**      | Exponer el juego hacia la red local                   |

------------

### ğŸ—ï¸ Arquitectura del despliegue

El flujo completo fue:

1. âœ”ï¸ Desarrollo del servidor en Node.js
2. âœ”ï¸ CreaciÃ³n de una imagen Docker
3. âœ”ï¸ Despliegue en Kubernetes mediante un Deployment con 3 rÃ©plicas
4. âœ”ï¸ ExposiciÃ³n del servicio mediante un NodePort
5. âœ”ï¸ Acceso desde el navegador al juego mediante la IP del Minikube

La arquitectura final luce asÃ­:

               +-------------------+
               |   Client/Browser  |
               +---------+---------+
                         |
                         | Socket.IO / HTTP
                         |
           +-------------+--------------+
           |      NodePort Service      |
           |        (juego-service)     |
           +-------------+--------------+
                         |
       -----------------------------------------
       |                |                 |
    +------+       +--------+        +--------+
    | Pod  |       |  Pod   |        |  Pod   |
    | #1   |       |  #2    |        |  #3    |
    +------+       +--------+        +--------+
    (Servidor)     (Servidor)        (Servidor)

------------


### ğŸš€ Resultado

DespuÃ©s del despliegue, el servicio quedÃ³ accesible mediante la URL generada por Minikube:

------------

### ğŸ§µğŸ”’ Manejo de Concurrencia: Hilos, SecciÃ³n CrÃ­tica, SemÃ¡foros y Mutex

Aunque el servidor del juego fue desarrollado con Node.js, el cual maneja la concurrencia mediante un Event Loop y no con hilos tradicionales como C o Java, el sistema implementado sÃ­ aplica los mismos principios teÃ³ricos de programaciÃ³n concurrente, especialmente por la naturaleza multicliente del juego.
Por ello en esta secciÃ³n explicamos cÃ³mo los conceptos de hilos, semÃ¡foros, mutex y secciÃ³n crÃ­tica se relacionan con el funcionamiento del servidor.

#### ğŸ§µ 1. Hilos (Threads)

En un servidor multijugador, es natural pensar en mÃºltiples hilos atendiendo a varios jugadores al mismo tiempo.

Aunque Node.js no usa hilos tradicionales para las solicitudes (usa el Event Loop), el efecto es similar:

- Cada cliente conectado actÃºa como un flujo independiente de eventos.
- Cada vez que un jugador envÃ­a una posiciÃ³n, se activa un evento del lado del servidor.
- Node.js administra todos esos eventos como si fueran â€œmicro-hilos cooperativosâ€.

En tÃ©rminos conceptuales:

| Concepto                  | Equivalente en el servidor                        |
| ------------------------- | ------------------------------------------------- |
| **Hilo**                  | Evento de Socket.IO por jugador                   |
| **Ejecuciones paralelas** | MÃºltiples eventos `move` llegando al mismo tiempo |
| **AtenciÃ³n concurrente**  | MÃºltiples clientes conectados simultÃ¡neamente     |

#### ğŸ”’ 2. SecciÃ³n crÃ­tica

La secciÃ³n crÃ­tica aparece cuando mÃºltiples jugadores actualizan informaciÃ³n compartida, en este caso:

ğŸ‘‰ El objeto global players
Donde se guardan todas las posiciones de todos los jugadores.

Â¿Por quÃ© es secciÃ³n crÃ­tica?

- Varias conexiones (jugadores) pueden enviar movimientos al mismo tiempo.
- Todos estos movimientos intentan modificar la misma estructura de datos compartida.
- Si el acceso no se administra correctamente, podrÃ­a generarse informaciÃ³n inconsistente.

Node.js evita este problema al ejecutar el Event Loop de manera secuencial, garantizando que solo una operaciÃ³n se ejecute a la vez, lo cual protege implÃ­citamente la secciÃ³n crÃ­tica.

ğŸš¦ 3. SemÃ¡foros y Mutex

Aunque no se usan explÃ­citamente (como en un lenguaje de bajo nivel), los conceptos sÃ­ aplican:

ğŸ” Mutex

Un mutex asegura acceso exclusivo a un recurso.
En este servidor, el Event Loop funciona como un mutex global, ya que no permite que dos callbacks accedan simultÃ¡neamente a la variable compartida players.

ğŸš¦ SemÃ¡foro

Un semÃ¡foro controla cuÃ¡ntos hilos pueden acceder al mismo recurso.
En nuestro caso:

- Socket.IO actÃºa como un manejador de concurrencia, asegurando que los eventos se procesen ordenadamente.
- Aunque no hay un semÃ¡foro fÃ­sico, sÃ­ existe un control del flujo de eventos, lo cual es equivalente conceptualmente.
http://<minikube-ip>:30080

------------

### ğŸ“Œ ConclusiÃ³n

Fue posible construir y desplegar exitosamente el servidor multijugador, y comprobar que Kubernetes ejecuta mÃºltiples rÃ©plicas del mismo servicio.

Sin embargo, debido a que el ambiente se probÃ³ Ãºnicamente desde un solo computador, no fue posible visualizar mÃºltiples jugadores conectados simultÃ¡neamente desde diferentes dispositivos. Para probar la interacciÃ³n real entre varios jugadores, serÃ­a necesario que otros dispositivos se conecten dentro de la misma red local al servicio expuesto por Minikube.

Aun asÃ­, la prÃ¡ctica permitiÃ³ comprender:

- CÃ³mo Docker empaqueta un proyecto Node.js
- CÃ³mo Kubernetes escala servicios mediante rÃ©plicas
- CÃ³mo exponer aplicaciones interactivas con NodePort
- Y cÃ³mo manejar comunicaciÃ³n en tiempo real con Socket.IO
